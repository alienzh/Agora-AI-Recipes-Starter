# ğŸŒŸ è‡ªå®šä¹‰ LLM Python ç¤ºä¾‹ä»£ç 

> Agora å¯¹è¯å¼ AI å¼•æ“æ”¯æŒè‡ªå®šä¹‰å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åŠŸèƒ½ã€‚æ‚¨å¯ä»¥å‚è€ƒæœ¬é¡¹ç›®ä»£ç æ¥å®ç°è‡ªå®šä¹‰å¤§è¯­è¨€æ¨¡å‹åŠŸèƒ½ã€‚

æœ¬æ–‡æ¡£æä¾›äº†å®ç°è‡ªå®šä¹‰å¤§è¯­è¨€æ¨¡å‹åŠŸèƒ½çš„ Python ç¤ºä¾‹ä»£ç ã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒå‡†å¤‡

- Python 3.10+

Python è™šæ‹Ÿç¯å¢ƒï¼š

```bash
python3 -m venv venv
source venv/bin/activate
```

### é…ç½® LLM API ç«¯ç‚¹ï¼ˆå¯é€‰ï¼‰

å¦‚æœéœ€è¦ä½¿ç”¨é OpenAI çš„ LLM æœåŠ¡ï¼Œå¯ä»¥ä¿®æ”¹ `custom_llm.py` æ–‡ä»¶ä¸­çš„ `LLM_BASE_URL` å¸¸é‡ï¼š

```python
# åœ¨ custom_llm.py æ–‡ä»¶ä¸­ï¼ˆç¬¬ 30 è¡Œå·¦å³ï¼‰
LLM_BASE_URL = "https://api.openai.com/v1"  # ä¿®æ”¹ä¸ºæ‚¨çš„ LLM æä¾›å•†ç«¯ç‚¹
```

**é‡è¦æç¤º**ï¼š
- æœåŠ¡å™¨éœ€è¦å…¼å®¹ OpenAI Chat Completions API æ ¼å¼çš„ LLM æœåŠ¡
- API Key å¿…é¡»é€šè¿‡è¯·æ±‚çš„ `Authorization` header æä¾›ï¼ˆæ ¼å¼ï¼š`Bearer <your-api-key>`ï¼‰
- é»˜è®¤ä½¿ç”¨ OpenAI API ç«¯ç‚¹ï¼Œå¦‚éœ€ä½¿ç”¨å…¶ä»–æœåŠ¡ï¼Œè¯·ä¿®æ”¹ä»£ç ä¸­çš„ `LLM_BASE_URL` å¸¸é‡

### å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

### è¿è¡Œç¤ºä¾‹ä»£ç 

```bash
python3 custom_llm.py
```

æœåŠ¡å™¨è¿è¡Œåï¼Œæ‚¨å°†çœ‹åˆ°ä»¥ä¸‹è¾“å‡ºï¼š

```bash
INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
```

ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æµ‹è¯•æœåŠ¡å™¨ï¼š

```bash
curl -X POST http://localhost:8000/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer your-api-key-here" \
  -d '{"messages": [{"role": "user", "content": "Hello, how are you?"}], "stream": true, "model": "gpt-4o-mini"}'
```

**æ³¨æ„**ï¼š
- å°† `your-api-key-here` æ›¿æ¢ä¸ºæ‚¨çš„å®é™… LLM API Key
- API Key å¿…é¡»é€šè¿‡ `Authorization` header ä¼ é€’ï¼ˆæ ¼å¼ï¼š`Bearer <your-api-key>`ï¼‰
- å¦‚éœ€ä½¿ç”¨å…¶ä»– LLM æœåŠ¡ï¼Œè¯·ä¿®æ”¹ `custom_llm.py` ä¸­çš„ `LLM_BASE_URL` å¸¸é‡

## ğŸ”„ æ¶æ„å’Œæµç¨‹å›¾

### ç³»ç»Ÿæ¶æ„

```mermaid
flowchart LR
    Client-->|POST Request|Server

    subgraph Server[Custom LLM Server]
        Basic["chat/completions"]
        RAG["rag/chat/completions"]
        Audio["audio/chat/completions"]
    end


    Server-->|SSE Response|Client

    Server-->|API call|OpenAI[OpenAI API]
    OpenAI-->|Stream Response|Server

    subgraph Knowledge
        KB[Knowledge Base]
    end

    RAG-.->|Retrieval|KB
```

æœ‰å…³ä¸‰ä¸ªç«¯ç‚¹åŠå…¶è¯·æ±‚æµç¨‹çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜… [è¯·æ±‚æµç¨‹å›¾](#ğŸ“-è¯·æ±‚æµç¨‹å›¾) éƒ¨åˆ†ã€‚

## ğŸ“– åŠŸèƒ½è¯´æ˜

### æ”¯æŒ LLM æä¾›å•†

æ­¤æœåŠ¡å™¨æ”¯æŒä»»ä½•å…¼å®¹ OpenAI Chat Completions API æ ¼å¼çš„ LLM æœåŠ¡ã€‚åªéœ€ç¡®ä¿æ‚¨çš„ LLM æœåŠ¡æä¾›ä¸ OpenAI API å…¼å®¹çš„æ¥å£ï¼Œå¹¶é€šè¿‡ `LLM_BASE_URL` é…ç½®ç›¸åº”çš„ç«¯ç‚¹å³å¯ã€‚

### åŸºç¡€è‡ªå®šä¹‰å¤§è¯­è¨€æ¨¡å‹

> è¦æˆåŠŸé›†æˆ Agora å¯¹è¯å¼ AI å¼•æ“ï¼Œæ‚¨çš„è‡ªå®šä¹‰å¤§æ¨¡å‹æœåŠ¡å¿…é¡»æä¾›ä¸ OpenAI Chat Completions API å…¼å®¹çš„æ¥å£ã€‚

`/chat/completions` ç«¯ç‚¹å®ç°äº†åŸºç¡€èŠå¤©å®ŒæˆåŠŸèƒ½ã€‚

### å®ç°æ£€ç´¢å¢å¼ºçš„è‡ªå®šä¹‰å¤§è¯­è¨€æ¨¡å‹

> å¦‚æœæ‚¨æƒ³æé«˜ä»£ç†å“åº”çš„å‡†ç¡®æ€§å’Œç›¸å…³æ€§ï¼Œå¯ä»¥ä½¿ç”¨æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰åŠŸèƒ½ã€‚è¿™å…è®¸æ‚¨çš„è‡ªå®šä¹‰å¤§æ¨¡å‹ä»ç‰¹å®šçŸ¥è¯†åº“ä¸­æ£€ç´¢ä¿¡æ¯ï¼Œå¹¶å°†æ£€ç´¢ç»“æœä½œä¸ºä¸Šä¸‹æ–‡æä¾›ç»™å¤§æ¨¡å‹ä»¥ç”Ÿæˆç­”æ¡ˆã€‚

`/rag/chat/completions` ç«¯ç‚¹æ¼”ç¤ºäº†ä½¿ç”¨åŸºäºå†…å­˜çš„çŸ¥è¯†å­˜å‚¨çš„ç®€å• RAG å®ç°ã€‚

### å®ç°å¤šæ¨¡æ€è‡ªå®šä¹‰å¤§è¯­è¨€æ¨¡å‹

> å¤šæ¨¡æ€ LLM å¯ä»¥å¤„ç†å’Œç”Ÿæˆæ–‡æœ¬ã€å›¾åƒå’ŒéŸ³é¢‘å†…å®¹ã€‚

`/audio/chat/completions` ç«¯ç‚¹ä½¿ç”¨è½¬å½•å’ŒéŸ³é¢‘æ•°æ®å—æ¨¡æ‹ŸéŸ³é¢‘å“åº”ã€‚

## ğŸ“ è¯·æ±‚æµç¨‹å›¾

### åŸºç¡€ LLM è¯·æ±‚æµç¨‹

```mermaid
sequenceDiagram
    participant Client
    participant Server as Custom LLM Server
    participant OpenAI

    Client->>Server: POST /chat/completions
    Note over Client,Server: åŒ…å« messages, model, stream å‚æ•°

    Server->>OpenAI: åˆ›å»º chat.completions æµ

    loop å¯¹äºæ¯ä¸ªæ•°æ®å—
        OpenAI->>Server: æµå¼æ•°æ®å—
        Server->>Client: SSE data: chunk
    end

    Server->>Client: SSE data: [DONE]
```

### RAG å¢å¼ºçš„ LLM è¯·æ±‚æµç¨‹

```mermaid
sequenceDiagram
    participant Client
    participant Server as Custom LLM Server
    participant KB as Knowledge Base
    participant OpenAI

    Client->>Server: POST /rag/chat/completions
    Note over Client,Server: åŒ…å« messages, model å‚æ•°

    Server->>Client: SSE data: "ç­‰å¾…æ¶ˆæ¯"

    Server->>KB: æ‰§è¡Œ RAG æ£€ç´¢
    KB->>Server: è¿”å›ç›¸å…³ä¸Šä¸‹æ–‡

    Server->>Server: ä½¿ç”¨ä¸Šä¸‹æ–‡é‡æ„æ¶ˆæ¯

    Server->>OpenAI: ä½¿ç”¨ä¸Šä¸‹æ–‡åˆ›å»º chat.completions æµ

    loop å¯¹äºæ¯ä¸ªæ•°æ®å—
        OpenAI->>Server: æµå¼æ•°æ®å—
        Server->>Client: SSE data: chunk
    end

    Server->>Client: SSE data: [DONE]
```

### å¤šæ¨¡æ€éŸ³é¢‘ LLM è¯·æ±‚æµç¨‹

```mermaid
sequenceDiagram
    participant Client
    participant Server as Custom LLM Server
    participant FS as File System

    Client->>Server: POST /audio/chat/completions
    Note over Client,Server: åŒ…å« messages, model å‚æ•°

    alt æ–‡ä»¶å­˜åœ¨
        Server->>FS: è¯»å–æ–‡æœ¬æ–‡ä»¶
        FS->>Server: è¿”å›æ–‡æœ¬å†…å®¹

        Server->>FS: è¯»å–éŸ³é¢‘æ–‡ä»¶
        FS->>Server: è¿”å›éŸ³é¢‘æ•°æ®

        Server->>Client: SSE data: transcript

        loop å¯¹äºæ¯ä¸ªéŸ³é¢‘å—
            Server->>Client: SSE data: audio chunk
            Note over Server,Client: æ•°æ®å—ä¹‹é—´æœ‰å°çš„å»¶è¿Ÿ
        end
    else æ–‡ä»¶ä¸å­˜åœ¨
        Server->>Server: ç”Ÿæˆæ¨¡æ‹Ÿå“åº”
        Server->>Client: SSE data: æ¨¡æ‹Ÿè½¬å½•

        loop æ¨¡æ‹Ÿæ•°æ®å—
            Server->>Client: SSE data: éšæœºéŸ³é¢‘æ•°æ®
            Note over Server,Client: æ•°æ®å—ä¹‹é—´æœ‰å°çš„å»¶è¿Ÿ
        end
    end

    Server->>Client: SSE data: [DONE]
```

## ğŸ“š èµ„æº

- ğŸ“– æŸ¥çœ‹æˆ‘ä»¬çš„ [å¯¹è¯å¼ AI å¼•æ“æ–‡æ¡£](https://doc.agora.io/doc/convoai/restful/landing-page) äº†è§£æ›´å¤šè¯¦æƒ…
- ğŸ§© è®¿é—® [Agora SDK ç¤ºä¾‹](https://github.com/AgoraIO) è·å–æ›´å¤šæ•™ç¨‹å’Œç¤ºä¾‹ä»£ç 
- ğŸ‘¥ åœ¨ [Agora å¼€å‘è€…ç¤¾åŒº](https://github.com/AgoraIO-Community) æ¢ç´¢ç”±å¼€å‘è€…ç¤¾åŒºç®¡ç†çš„é«˜è´¨é‡ä»“åº“
- ğŸ’¬ å¦‚æœ‰ä»»ä½•é—®é¢˜ï¼Œæ¬¢è¿åœ¨ [Stack Overflow](https://stackoverflow.com/questions/tagged/agora.io) ä¸Šæé—®

## ğŸ’¡ åé¦ˆ

- ğŸ¤– å¦‚æœæ‚¨å¯¹ç¤ºä¾‹é¡¹ç›®æœ‰ä»»ä½•é—®é¢˜æˆ–å»ºè®®ï¼Œæ¬¢è¿æäº¤ issueã€‚

## ğŸ“œ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ã€‚
