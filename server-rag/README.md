# ğŸŒŸ RAG å¢å¼ºçš„ LLM Python ç¤ºä¾‹ä»£ç 

> Agora å¯¹è¯å¼ AI å¼•æ“æ”¯æŒæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰åŠŸèƒ½ã€‚æœ¬é¡¹ç›®æä¾›äº†å®ç° RAG å¢å¼ºçš„è‡ªå®šä¹‰å¤§è¯­è¨€æ¨¡å‹æœåŠ¡çš„ Python ç¤ºä¾‹ä»£ç ã€‚

## ğŸ“– ä»€ä¹ˆæ˜¯ RAGï¼Ÿ

æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRetrieval-Augmented Generationï¼ŒRAGï¼‰æ˜¯ä¸€ç§ç»“åˆä¿¡æ¯æ£€ç´¢å’Œç”Ÿæˆå¼ AI çš„æŠ€æœ¯ã€‚å®ƒé€šè¿‡ä»¥ä¸‹æ­¥éª¤å·¥ä½œï¼š

1. **æ£€ç´¢ï¼ˆRetrievalï¼‰**ï¼šä»çŸ¥è¯†åº“ä¸­æ£€ç´¢ä¸ç”¨æˆ·æŸ¥è¯¢ç›¸å…³çš„ä¿¡æ¯
2. **å¢å¼ºï¼ˆAugmentationï¼‰**ï¼šå°†æ£€ç´¢åˆ°çš„ä¿¡æ¯ä½œä¸ºä¸Šä¸‹æ–‡æ·»åŠ åˆ°ç”¨æˆ·æŸ¥è¯¢ä¸­
3. **ç”Ÿæˆï¼ˆGenerationï¼‰**ï¼šLLM åŸºäºå¢å¼ºåçš„ä¸Šä¸‹æ–‡ç”Ÿæˆå›ç­”

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒå‡†å¤‡

- Python 3.10+

åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼š

```bash
python3 -m venv venv
source venv/bin/activate
```

### é…ç½® LLM API ç«¯ç‚¹

ä¿®æ”¹ `rag_llm.py` æ–‡ä»¶ä¸­çš„ `LLM_BASE_URL` å¸¸é‡ï¼š

```python
LLM_BASE_URL = "https://api.deepseek.com"  # ä¿®æ”¹ä¸ºæ‚¨çš„ LLM æä¾›å•†ç«¯ç‚¹
```

**é‡è¦æç¤º**ï¼š
- `base_url` ä¸åº”åŒ…å« `/chat/completions` è·¯å¾„ï¼ŒAsyncOpenAI å®¢æˆ·ç«¯ä¼šè‡ªåŠ¨æ·»åŠ 
- API Key å¿…é¡»é€šè¿‡è¯·æ±‚çš„ `Authorization` header æä¾›ï¼ˆæ ¼å¼ï¼š`Bearer <your-api-key>`ï¼‰

### é…ç½®çŸ¥è¯†åº“

ç¼–è¾‘ `knowledge_base.json` æ–‡ä»¶æ¥æ·»åŠ æ‚¨çš„çŸ¥è¯†åº“å†…å®¹ï¼š

```json
{
  "category1": [
    "æ‚¨çš„çŸ¥è¯†åº“å†…å®¹ 1",
    "æ‚¨çš„çŸ¥è¯†åº“å†…å®¹ 2"
  ],
  "category2": [
    "æ›´å¤šå†…å®¹..."
  ]
}
```

**è¿›é˜¶**ï¼šå¯ä»¥æ›¿æ¢ä¸ºå‘é‡æ•°æ®åº“ï¼ˆå¦‚ Chromaã€Pineconeã€Weaviateï¼‰æˆ–ä½¿ç”¨åµŒå…¥æ¨¡å‹è¿›è¡Œè¯­ä¹‰æœç´¢ã€‚

### å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

### è¿è¡ŒæœåŠ¡

```bash
python3 rag_llm.py
```

æœåŠ¡å™¨è¿è¡Œåï¼Œæ‚¨å°†çœ‹åˆ°ï¼š

```bash
INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
```

### æµ‹è¯•æœåŠ¡

```bash
curl -X POST http://localhost:8000/rag/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer your-api-key-here" \
  -d '{"messages": [{"role": "user", "content": "ä»€ä¹ˆæ˜¯ Agoraï¼Ÿ"}], "stream": true, "model": "your-model-name"}'
```

### éªŒè¯çŸ¥è¯†åº“æ˜¯å¦è¢«è§¦å‘

å¯åŠ¨æœåŠ¡åï¼Œæ—¥å¿—ä¸­ä¼šæ˜¾ç¤º RAG æ£€ç´¢çš„è¯¦ç»†ä¿¡æ¯ï¼š

```
ğŸ” RAG Retrieval: Searching knowledge base for query: 'ä»€ä¹ˆæ˜¯ Agoraï¼Ÿ'
ğŸ“š RAG Retrieval: Found 3 relevant chunks
ğŸ¯ Knowledge Base Match: category='agora', score=2, doc_preview='Agora æä¾›å®æ—¶é€šä¿¡è§£å†³æ–¹æ¡ˆ...'
âœ… RAG Context Retrieved: 245 characters
ğŸ“ RAG Messages Refactored: Added context to 2 messages
```

## ğŸ”„ RAG å·¥ä½œæµç¨‹

```mermaid
sequenceDiagram
    participant Client
    participant Server as RAG LLM Server
    participant KB as Knowledge Base
    participant LLM as LLM Provider

    Client->>Server: POST /rag/chat/completions
    Note over Client,Server: åŒ…å« messages, model å‚æ•°

    Server->>Client: SSE data: "ç­‰å¾…æ¶ˆæ¯"

    Server->>KB: æ‰§è¡Œ RAG æ£€ç´¢
    KB->>Server: è¿”å›ç›¸å…³ä¸Šä¸‹æ–‡

    Server->>Server: ä½¿ç”¨ä¸Šä¸‹æ–‡é‡æ„æ¶ˆæ¯

    Server->>LLM: ä½¿ç”¨ä¸Šä¸‹æ–‡åˆ›å»º chat.completions æµ

    loop å¯¹äºæ¯ä¸ªæ•°æ®å—
        LLM->>Server: æµå¼æ•°æ®å—
        Server->>Client: SSE data: chunk
    end

    Server->>Client: SSE data: [DONE]
```

## ğŸ“ æ ¸å¿ƒåŠŸèƒ½

### 1. RAG æ£€ç´¢ (`perform_rag_retrieval`)

å½“å‰å®ç°ä½¿ç”¨ç®€å•çš„å…³é”®è¯åŒ¹é…ã€‚æ‚¨å¯ä»¥æ›¿æ¢ä¸ºï¼š

- **å‘é‡æ•°æ®åº“**ï¼šä½¿ç”¨åµŒå…¥æ¨¡å‹å°†æ–‡æ¡£å’ŒæŸ¥è¯¢è½¬æ¢ä¸ºå‘é‡ï¼Œè¿›è¡Œç›¸ä¼¼åº¦æœç´¢
- **è¯­ä¹‰æœç´¢**ï¼šä½¿ç”¨ BERTã€Sentence-BERT ç­‰æ¨¡å‹è¿›è¡Œè¯­ä¹‰åŒ¹é…
- **æ··åˆæœç´¢**ï¼šç»“åˆå…³é”®è¯æœç´¢å’Œè¯­ä¹‰æœç´¢

### 2. æ¶ˆæ¯é‡æ„ (`refact_messages`)

å°†æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡æ·»åŠ åˆ°æ¶ˆæ¯åˆ—è¡¨çš„å¼€å¤´ä½œä¸ºç³»ç»Ÿæ¶ˆæ¯ï¼Œè®© LLM èƒ½å¤Ÿä½¿ç”¨è¿™äº›ä¸Šä¸‹æ–‡ä¿¡æ¯ç”Ÿæˆå›ç­”ã€‚

### 3. æµå¼å“åº”

æ”¯æŒ Server-Sent Events (SSE) æ ¼å¼çš„æµå¼å“åº”ï¼Œæä¾›å®æ—¶äº¤äº’ä½“éªŒã€‚

## ğŸ”§ è‡ªå®šä¹‰ RAG å®ç°

### ç®¡ç†çŸ¥è¯†åº“

é¡¹ç›®æä¾›äº† `knowledge_base.py` æ¨¡å—æ¥ç®¡ç†çŸ¥è¯†åº“ï¼š

```python
from knowledge_base import get_knowledge_base

# è·å–çŸ¥è¯†åº“å®ä¾‹
kb = get_knowledge_base()

# æ·»åŠ æ–‡æ¡£
kb.add_document("category", "Your document text here")

# æœç´¢æ–‡æ¡£
results = kb.search("your query", top_k=3)
```

### ä½¿ç”¨å‘é‡æ•°æ®åº“

ç¤ºä¾‹ï¼šä½¿ç”¨ Chroma å‘é‡æ•°æ®åº“

```python
import chromadb
from chromadb.config import Settings

# åˆå§‹åŒ– Chroma å®¢æˆ·ç«¯
chroma_client = chromadb.Client(Settings())

async def perform_rag_retrieval(messages, knowledge_base=None):
    query = extract_query_from_messages(messages)
    
    # æŸ¥è¯¢å‘é‡æ•°æ®åº“
    collection = chroma_client.get_collection("knowledge_base")
    results = collection.query(
        query_texts=[query],
        n_results=3
    )
    
    # è¿”å›æ£€ç´¢åˆ°çš„æ–‡æ¡£
    return "\n\n".join(results['documents'][0])
```

### ä½¿ç”¨åµŒå…¥æ¨¡å‹

ç¤ºä¾‹ï¼šä½¿ç”¨ OpenAI åµŒå…¥æ¨¡å‹

```python
from openai import AsyncOpenAI

async def perform_rag_retrieval(messages, knowledge_base=None):
    query = extract_query_from_messages(messages)
    client = AsyncOpenAI(api_key=api_key)
    
    # ç”ŸæˆæŸ¥è¯¢åµŒå…¥
    query_embedding = await client.embeddings.create(
        model="text-embedding-ada-002",
        input=query
    )
    
    # åœ¨å‘é‡æ•°æ®åº“ä¸­æœç´¢ç›¸ä¼¼æ–‡æ¡£
    # ... å®ç°å‘é‡ç›¸ä¼¼åº¦æœç´¢
    
    return retrieved_context
```

## ğŸ“š ç›¸å…³èµ„æº

- ğŸ“– æŸ¥çœ‹æˆ‘ä»¬çš„ [å¯¹è¯å¼ AI å¼•æ“æ–‡æ¡£](https://doc.agora.io/doc/convoai/restful/landing-page) äº†è§£æ›´å¤šè¯¦æƒ…
- ğŸ§© è®¿é—® [Agora SDK ç¤ºä¾‹](https://github.com/AgoraIO) è·å–æ›´å¤šæ•™ç¨‹å’Œç¤ºä¾‹ä»£ç 
- ğŸ‘¥ åœ¨ [Agora å¼€å‘è€…ç¤¾åŒº](https://github.com/AgoraIO-Community) æ¢ç´¢ç”±å¼€å‘è€…ç¤¾åŒºç®¡ç†çš„é«˜è´¨é‡ä»“åº“

## ğŸ’¡ åé¦ˆ

- ğŸ¤– å¦‚æœæ‚¨å¯¹ç¤ºä¾‹é¡¹ç›®æœ‰ä»»ä½•é—®é¢˜æˆ–å»ºè®®ï¼Œæ¬¢è¿æäº¤ issueã€‚

## ğŸ“œ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ã€‚

