# Agora Agent Starter Script (Vision)

[中文](README-CN.md) | English

Command-line script for starting and stopping Agora Conversational AI Agent (Vision version). All configuration is loaded from local environment variables.

## Use Cases

- Quick testing and experiencing Agora Conversational AI Agent's Vision functionality
- Use with mobile applications: start Agent via script, then join channel in app to experience Vision conversation
- Agent can get camera video data through video stream, supporting image input modality
- Scenarios requiring protection of server-side authentication information

## Prerequisites

- Python 3.6 or higher
- Network connection (for calling Agora REST API)
- Agora developer account [Console](https://console.shengwang.cn/)
- Created Agora project and obtained App ID
- Obtained REST API Basic Auth credentials (Key and Secret)
- Obtained Pipeline ID

## Install Dependencies

```bash
cd server-vision

# Create virtual environment
python3 -m venv venv

# Activate virtual environment
# Linux/macOS:
source venv/bin/activate
# Windows:
# venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

## Configuration

1. Copy example configuration file:

   ```bash
   cd server-vision
   cp .env.example .env.local
   ```

2. Edit `.env.local` file and fill in your actual configuration values:

```bash
# App ID (used to generate Token and start Agent)
AGORA_APP_ID=your_app_id_here

# App Certificate (used to generate Token, optional)
AGORA_APP_CERT=your_app_certificate_here

# Basic Auth credentials (used to call Agora REST API)
AGORA_BASIC_KEY=your_basic_key_here
AGORA_BASIC_SECRET=your_basic_secret_here

# Pipeline ID (used to start Agent)
AGORA_PIPELINE_ID=your_pipeline_id_here

# Channel name (channel Agent will join)
AGORA_CHANNEL_NAME=your_channel_name_here
```

## Pipeline Configuration

When creating Pipeline in [AI Studio](https://console-conversationai.shengwang.cn/product/ConversationAI/studio), you need to ensure the selected LLM supports Vision capability.

**Important Configuration Requirements**:

- **LLM Selection**: The selected LLM must support Vision capability, such as multimodal large models that support image understanding

**Note**:
- Vision functionality is enabled through request parameter `input_modalities: ["text", "image"]`, no additional Pipeline configuration needed
- If the selected LLM doesn't support Vision capability, even if the request includes image input modality, Agent cannot properly process Vision input

## Usage

### Start Agent (Vision Mode)

Run command directly to start Agent, using fixed configuration (Agent RTC UID: `2001`):

```bash
python agent_start_vision.py start
```

### Script Startup Flow

Complete flow when script executes `startAgent`:

1. **Generate Agent RTC UID and Token**
   - Agent RTC UID fixed value: `2001`
   - Call token generation service to generate Agent's RTC/RTM Token
   - API: `POST https://service.apprtc.cn/toolbox/v2/token/generate`

2. **RESTful Request to Start Agent**
   - Build request body containing LLM configuration
   - Send POST request to Agora REST API
   - API: `POST https://api.sd-rtn.com/cn/api/conversational-ai-agent/v2/projects/{app_id}/join/`
   - Request headers contain Basic Auth credentials
   - Request body example:

     ```json
     {
       "name": "<channel_name>",
       "pipeline_id": "<pipeline_id>",
       "properties": {
         "channel": "<channel_name>",
         "agent_rtc_uid": "2001",
         "remote_rtc_uids": ["*"],
         "token": "<agent_token>",
         "llm": {
           "input_modalities": ["text", "image"]
         }
       }
     }
     ```

3. **Save Agent ID**
   - Get `agent_id` from response
   - Save to `.agent_id` file for subsequent Agent stop operations

After successful startup, script will output:

- Agent ID
- Channel name
- Agent RTC UID
- LLM input modalities

### Stop Agent

```bash
python agent_start_vision.py stop
```

Optional parameters:

- `--agent-id`: Agent ID (optional, uses previous Agent ID if not provided)

Examples:
```bash
# Use previous Agent ID
python agent_start_vision.py stop

# Or specify Agent ID
python agent_start_vision.py stop --agent-id 1NT29X10YHxxxxxWJOXLYHNYB
```

## Vision Feature Description

This script enables Vision functionality by default. The script includes the following LLM configuration in the Agent start request:

```json
{
  "properties": {
    "llm": {
      "input_modalities": ["text", "image"]
    }
  }
}
```

- `agent_rtc_uid` fixed value: `2001`
- `input_modalities` set to `["text", "image"]`, enabling Agent to get camera video data through video stream
- Agent Token automatically generated by server, no manual configuration needed

Agent will run in Vision mode, supporting text and image input, can get camera video data through video stream.

## View Results

After starting Agent, you can use mobile applications to view results. Please refer to related mobile application README documentation.

**Note**: Channel name used in mobile application must match `AGORA_CHANNEL_NAME` in `.env.local`.

## License

Please refer to the LICENSE file in the project root directory.
